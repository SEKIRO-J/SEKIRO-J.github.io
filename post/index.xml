<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Hello World, This Is J</title>
    <link>/post/</link>
    <description>Recent content in Posts on Hello World, This Is J</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Apr 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Difference between Multi-Processing, Multi-threading and Coroutine</title>
      <link>/post/tcp/</link>
      <pubDate>Tue, 09 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/tcp/</guid>
      <description>How is a computer program executed? A program needs at least one thread to run on. And a coroutine live in a thread, a thread lives in process, a process lives in core, a core lives in a CPU.
 Multi-Processing usually refer to many processes execute in parallel. Process is smallest resource management unit, different process share different resource. Multi-Threading usually refer to many threads execute concurrently, when there are idle cores, threads can use idle cores to run in parallel.</description>
    </item>
    
    <item>
      <title>Pyspark</title>
      <link>/post/pysparkcheatsheet/</link>
      <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/pysparkcheatsheet/</guid>
      <description>1. initilaztion 1. spark session from pyspark.sql import SparkSession spark = SparkSession \ .builder \ .appName(&amp;quot;name&amp;quot;) \ .config(&amp;quot;spark.some.config.option&amp;quot;, &amp;quot;some-value&amp;quot;) \ .getOrCreate()  2. spark context 1. from spark session sc = spark.sparkContext  2. from spark context conf = SparkConf().setAppName(&amp;quot;KMeans&amp;quot;).setMaster(&amp;quot;local[*]&amp;quot;) sc = SparkContext(conf =conf) or sc = SparkContext.getOrCreate(conf)  2. paritition by index .mapPartitionsWithIndex(lambda idx, it: islice(it, 1, None) if idx == 0 else it)\ this get rid of the first line(rdd) in the file.</description>
    </item>
    
    <item>
      <title>Python CheatSheet</title>
      <link>/post/pythoncheatsheet/</link>
      <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/pythoncheatsheet/</guid>
      <description>This cheatsheet includes some very basic but easy to forget operations and some random notes. A good tutorial for beginner in Chinese 1. Decorator Syntax def decorator(func): def new_func(*args, **argkw): #add stuff print(&amp;quot;Hello World&amp;quot;) return func(*args, **argkw) return new_func @decorator def f(args): pass #run function f f() #result: #Hello World  2. Open file, read, write Open: f = open(“hello.text”, flag), flag: &#39;r&#39; = read, &#39;b&#39; = binary, &#39;w&#39; = write read sing line: f.</description>
    </item>
    
    <item>
      <title>Useful tool kit</title>
      <link>/post/toolkit/</link>
      <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/toolkit/</guid>
      <description>1. track memory usage line by line https://pypi.org/project/memory_profiler/
2. track run time for each line https://pypi.org/project/line_profiler/
3. regular expression https://docs.python.org/3/library/re.html
4. google word to vector, trained model GoogleNews-vectors-negative300.bin https://code.google.com/archive/p/word2vec/</description>
    </item>
    
    <item>
      <title>Pandas Cheat Sheet</title>
      <link>/post/pandascheatsheet/</link>
      <pubDate>Sat, 08 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/pandascheatsheet/</guid>
      <description> 1. Collect dataframe as dictionary .set_index([&amp;lsquo;a&amp;rsquo;,&amp;lsquo;b&amp;rsquo;]).T.to_dict(&amp;lsquo;list&amp;rsquo;)
2. Read in csv file format(transpose) https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html
3. count rows with same value df[col].value_counts()
4. display columns unlimit ( equivalent to spark df, with limit=False) pd.set_option(&#39;display.expand_frame_repr&#39;, False) Other settings: pd.set_option(&#39;display.height&#39;, 1000) pd.set_option(&#39;display.max_rows&#39;, 500) pd.set_option(&#39;display.max_columns&#39;, 500) pd.set_option(&#39;display.width&#39;, 1000)  5. remove all the rows with a value occur less than n times df[df.groupby(value).uid.transform(len) &amp;gt; n] or: df.groupby(by=value).filter(lambda x: len(x) &amp;gt; n)  </description>
    </item>
    
    <item>
      <title></title>
      <link>/post/nltk/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/post/nltk/</guid>
      <description> NLTK&amp;mdash; title: &amp;ldquo;NLTK&amp;rdquo; date: 2019-04-08T22:38:04+08:00
draft: false 1. tokenize https://www.nltk.org/_modules/nltk/tokenize.html
Support sentence, word, for 17 languages source code for sentence tokenizer: ``python def sent_tokenize(text, language=&#39;english&#39;): &amp;quot;&amp;quot;&amp;quot; Return a sentence-tokenized copy of *text*, using NLTK&#39;s recommended sentence tokenizer (currently :class:.PunktSentenceTokenizer` for the specified language).
:param text: text to split into sentences :param language: the model name in the Punkt corpus &amp;quot;&amp;quot;&amp;quot; tokenizer = load(&#39;tokenizers/punkt/{0}.pickle&#39;.format(language)) return tokenizer.tokenize(text)  word tokenizer: word_tokenize(text, language=&amp;lsquo;english&amp;rsquo;, preserve_line=False) perserve_line == false, then call sentence tokenizer first, otherwise, don&amp;rsquo;t </description>
    </item>
    
    <item>
      <title></title>
      <link>/post/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/post/readme/</guid>
      <description>PythonNotes Cheat notes for Pyspark, Pandas, Numpy, NLTK, Keras, Tensorflow and etc</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/stackeditcheatsheet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/post/stackeditcheatsheet/</guid>
      <description>Welcome to StackEdit! Hi! I&amp;rsquo;m your first Markdown file in StackEdit. If you want to learn about StackEdit, you can read me. If you want to play with Markdown, you can edit me. Once you have finished with me, you can create new files by opening the file explorer on the left corner of the navigation bar.
Files StackEdit stores your files in your browser, which means all your files are automatically saved locally and are accessible offline!</description>
    </item>
    
  </channel>
</rss>